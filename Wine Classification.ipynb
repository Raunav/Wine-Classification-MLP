# Importing required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold

# Reading the dataset
wine = pd.read_csv("wine.csv", delimiter=",")

# Separating features (X) and target variable (y)
x = wine.drop("Wine", axis=1)
y = wine['Wine']

# Normalizing the features using MinMaxScaler
scaler = MinMaxScaler()
x = scaler.fit_transform(x)

# Initializing the Multi-Layer Perceptron model
mlp_model = MLPClassifier(max_iter=1000, activation='tanh', solver='lbfgs')

# Performing 5-fold cross-validation for the MLP model
kf = KFold(n_splits=5, random_state=10, shuffle=True)
mlp_scores = []

for train_index, test_index in kf.split(x):
    x_train, x_test = x[train_index], x[test_index]
    y_train, y_test = y[train_index], y[test_index]
    mlp_model.fit(x_train, y_train)
    predictions = mlp_model.predict(x_test)
    mlp_scores.append(accuracy_score(y_test, predictions))

# Calculating the average accuracy of the MLP model
mlp_avg_accuracy = sum(mlp_scores) / len(mlp_scores)
print(f"Accuracy score of MLP Model: {mlp_avg_accuracy * 100:.2f}%")

# Simulating a random model for comparison
random_model_scores = []

for train_index, test_index in kf.split(x):
    y_test = y[test_index]
    random_predictions = np.random.randint(low=1, high=4, size=len(y_test))  # Random predictions
    random_model_scores.append(accuracy_score(y_test, random_predictions))

# Calculating the average accuracy of the random model
random_avg_accuracy = sum(random_model_scores) / len(random_model_scores)
print(f"Accuracy score of Random Model: {random_avg_accuracy * 100:.2f}%")

# Plotting the accuracy scores of the two models across folds
plt.plot(range(len(mlp_scores)), mlp_scores, label="MLP Model", color="blue")
plt.plot(range(len(random_model_scores)), random_model_scores, label="Random Model", color="green")
plt.title("Accuracy Scores of the Two Models", fontsize=15)
plt.ylabel("Accuracy Scores", fontsize=15)
plt.xlabel("Folds", fontsize=15)
plt.legend(loc="center", fontsize=12)
plt.show()
